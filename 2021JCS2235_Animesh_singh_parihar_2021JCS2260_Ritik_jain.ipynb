{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import math\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_correcetion(img_original,gamma = 1.4):\n",
    "    lookUpTable = np.empty((1,256), np.uint8)\n",
    "    for i in range(256):\n",
    "        lookUpTable[0,i] = np.clip(pow(i / 255.0, gamma) * 255.0, 0, 255)\n",
    "    res = cv2.LUT(img_original, lookUpTable)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Localization(images):    \n",
    "    \n",
    "    boundary=[]\n",
    "    centers=[]\n",
    "\n",
    "    for img in images:\n",
    "\n",
    "        blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "        maskimage = cv2.inRange(blur, 0, 70)\n",
    "        output = cv2.bitwise_and(blur, maskimage)\n",
    "\n",
    "        edged = cv2.Canny(output, 100, 220)\n",
    "\n",
    "        edged_gamma = gamma_correcetion(edged)\n",
    "\n",
    "        circles = cv2.HoughCircles(edged_gamma, cv2.HOUGH_GRADIENT, 10, 100)\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        cv2.circle(img,(circles[0][0][0],circles[0][0][1]),circles[0][0][2],(0,255,0),2)\n",
    "        cv2.circle(img,(circles[0][0][0],circles[0][0][1]),circles[0][0][2]+40,(0,255,0),2)\n",
    "\n",
    "        boundary.append(img)\n",
    "        centers.append([circles[0][0][0],circles[0][0][1],circles[0][0][2]])\n",
    "        \n",
    "    return boundary,centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalization(boundary,centers):\n",
    "    \n",
    "    img_lst = [i for i in boundary]\n",
    "    iris_radius,totalsamples = 40,360\n",
    "    pival = 2*np.pi\n",
    "    normalized=[]\n",
    "    i=0\n",
    "\n",
    "    for img in img_lst:\n",
    "        center_x,center_y,radius_pupil = centers[i][0],centers[i][1],int(centers[i][2])\n",
    "        polar,samples = np.zeros((iris_radius, totalsamples)),np.linspace(0,pival, totalsamples)[:-1]\n",
    "        for r in range(iris_radius):\n",
    "            for angle in samples:\n",
    "                x,y = int((r+radius_pupil)*np.cos(angle)+center_x),int((r+radius_pupil)*np.sin(angle)+center_y)\n",
    "                try:\n",
    "                    polar[r][int((angle*totalsamples)/(pival))] = img[y][x]\n",
    "                except IndexError:\n",
    "                    pass\n",
    "                continue\n",
    "        normalized.append(cv2.resize(polar,(512,48)))\n",
    "        i+=1\n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gabor_filter(x, y, dx, dy, f):\n",
    "    val = np.cos(2*np.pi*f*math.sqrt(x **2 + y**2))\n",
    "    mul_a = np.exp(-0.5*(x**2 / dx**2 + y**2 / dy**2))\n",
    "    mul_b = (1/(2*math.pi*dx*dy))\n",
    "    gb = mul_b * mul_a * val\n",
    "    return gb\n",
    "\n",
    "def get_std(grid):\n",
    "    absolute = np.absolute(grid)\n",
    "    mean = np.mean(absolute)\n",
    "    std = np.mean(np.absolute(absolute-mean))\n",
    "    return mean,std\n",
    "\n",
    "def get_vec(convolvedtrain1,convolvedtrain2):\n",
    "\n",
    "    feature_vec=[]\n",
    "\n",
    "    for i in range(6):\n",
    "            for j in range(64):\n",
    "\n",
    "                start_height,end_height = i*8,i*8+8\n",
    "                start_wid,end_wid = j*8,j*8+8\n",
    "\n",
    "                grid1,grid2 = convolvedtrain1[start_height:end_height, start_wid:end_wid],convolvedtrain2[start_height:end_height, start_wid:end_wid]\n",
    "\n",
    "                mean1,std1 = get_std(grid1)\n",
    "                mean2,std2 = get_std(grid2)\n",
    "\n",
    "                feature_vec.append(mean1)\n",
    "                feature_vec.append(std1)\n",
    "                feature_vec.append(mean2)\n",
    "                feature_vec.append(std2)\n",
    "\n",
    "    return feature_vec\n",
    "\n",
    "def FeatureExtraction(enhanced):\n",
    "\n",
    "    feature_vector=[]\n",
    "    filter1 = np.zeros((8,8))\n",
    "    filter2 = filter1\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            filter1[i,j] = gabor_filter((-4+j),(-4+i),3,1.5,0.67)\n",
    "\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            filter2[i,j] = gabor_filter((-4+j),(-4+i),4,1.5,0.67)\n",
    "    \n",
    "    for i in range(len(enhanced)):\n",
    "        img = enhanced[i]\n",
    "        img_roi = img[:48,:]\n",
    "        feature_vector.append(get_vec(scipy.signal.convolve2d(img_roi,filter1,mode='same'),scipy.signal.convolve2d(img_roi,filter2,mode='same')))\n",
    "\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dk = []\n",
    "for num in range(1,11):\n",
    "    images  = []\n",
    "    for img in glob.glob('D:/IITD_M.tech/Sem_2/Biometric_security/Assignment_2/IrisRecognition-master/CASIA1_train/' + str(num) + '/*.jpg'):\n",
    "        n= cv2.imread(img)\n",
    "        n = cv2.cvtColor(n, cv2.COLOR_BGR2GRAY)\n",
    "        n = cv2.resize(n, (200, 200))\n",
    "        images.append(n)\n",
    "\n",
    "    # print(len(images_train))\n",
    "    # cv2.imshow('normalized_image',images_train[1])\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    boundary,centers = Localization(images)\n",
    "    normalized = Normalization(boundary,centers)\n",
    "\n",
    "    # cv2.imshow('normalized_image',normalized_train[0])\n",
    "    # cv2.waitKey(0)\n",
    "\n",
    "    enhanced=[]\n",
    "    for res in normalized:\n",
    "        res = res.astype(np.uint8)\n",
    "        im=cv2.equalizeHist(res)\n",
    "        enhanced.append(im)\n",
    "        \n",
    "    feature_vector = FeatureExtraction(enhanced)\n",
    "    Dk.append(feature_vector)\n",
    "\n",
    "arr = []\n",
    "for i in Dk:\n",
    "    for j in i:\n",
    "        arr.append(j)\n",
    "\n",
    "D = np.array(arr)\n",
    "D = np.transpose(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1536, 30)\n"
     ]
    }
   ],
   "source": [
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = []\n",
    "path_of_query = 'D:/IITD_M.tech/Sem_2/Biometric_security/Assignment_2/IrisRecognition-master/CASIA1_test/7/007_1_4.jpg'\n",
    "n_test = cv2.imread(path_of_query)\n",
    "n_test = cv2.cvtColor(n_test, cv2.COLOR_BGR2GRAY)\n",
    "n_test = cv2.resize(n_test, (200, 200))\n",
    "\n",
    "cv2.imshow('img',n_test)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "images_test.append(n_test)\n",
    "boundary_test,centers_test = Localization(images_test)\n",
    "\n",
    "cv2.imshow('boundary_test',boundary_test[0])\n",
    "cv2.waitKey(0)\n",
    "\n",
    "normalized_test = Normalization(boundary_test,centers_test)\n",
    "\n",
    "# cv2.imshow('normalized_image',normalized_test[0])\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "enhanced_test=[]\n",
    "for res in normalized_test:\n",
    "    res = res.astype(np.uint8)\n",
    "    im=cv2.equalizeHist(res)\n",
    "    enhanced_test.append(im)\n",
    "\n",
    "cv2.imshow('enhanced_image',enhanced_test[0])\n",
    "cv2.waitKey(0)\n",
    "\n",
    "feature_vector_test = FeatureExtraction(enhanced_test)\n",
    "feature_vector_test = feature_vector_test[0]\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_function(cl):\n",
    "    \n",
    "    delta = []\n",
    "\n",
    "    for i in range(1,11):\n",
    "        if i == cl:\n",
    "            delta.append(1)\n",
    "            delta.append(1)\n",
    "            delta.append(1)\n",
    "        else:\n",
    "            delta.append(0)\n",
    "            delta.append(0)\n",
    "            delta.append(0)\n",
    "    \n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resudl_error(y,D,values_m):\n",
    "    \n",
    "    residual_error = []\n",
    "\n",
    "    for i in range(1,11):\n",
    "        delta = char_function(i)\n",
    "        # print(delta)\n",
    "        a = np.linalg.norm((y - D.dot(delta)))\n",
    "        residual_error.append(a)\n",
    "\n",
    "    residual_error = np.array(residual_error)\n",
    "    print(residual_error)\n",
    "\n",
    "    c = math.floor(values_m/3)+1\n",
    "    min_er = residual_error.argmin() + 1\n",
    "    \n",
    "    return residual_error,min_er,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125.20792253 122.84674057 120.20304239 123.44683683 120.67157387\n",
      " 121.65415054 108.8473496  116.23086876 125.37356834 119.19445376]\n",
      "The image belongs to the class : 7\n"
     ]
    }
   ],
   "source": [
    "# Matching \n",
    "\n",
    "m = 1536\n",
    "n = 30\n",
    "epsilon = 0.1\n",
    "y = np.array(feature_vector_test)\n",
    "\n",
    "alpha = cp.Variable(n)\n",
    "soc_objective = cp.Minimize(cp.norm(alpha,1))\n",
    "soc_constraints = [cp.norm((D @ alpha - y),2)<=epsilon]\n",
    "\n",
    "soc_prob = cp.Problem(soc_objective,soc_constraints)\n",
    "result = soc_prob.solve()\n",
    "\n",
    "values = alpha.value\n",
    "values_m = values.argmin() \n",
    "\n",
    "residual_error,min_er,cls = resudl_error(y,D,values_m)\n",
    "\n",
    "print(\"The image belongs to the class : {}\".format(min_er))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87950a251cf2bda580265fe4f2df9b92b10185591644656ac80624246b56a1ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
